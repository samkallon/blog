---
title: Real-Time-Rendering-4 学习笔记
date: 2024-04-30 16:03:16
tags: [学习笔记, 图形学]
index_img: /img/rtr4.png
---

{% asset_img img.png 1212%}

## 概述
最近研究Cesium框架，每每涉及到图形学底层相关的内容，就倍感吃力，所以想系统地把图形学的基础好好的夯实一下。
于是选择了**Real-Time-Rendering-4**作为学习图形学的入门书籍，目前是打算一个月左右先完整的过一遍，图形学博大精深，可不是一年两年就能学会的，目前也只是了解一些皮毛，对顶点/片源着色器，还有glsl有一些初步的了解。

## 图形渲染管线 (The Graphics Rendering Pipeline)

> Anonymous —— “A chain is no stronger than its weakest link.”
> 
> 佚名 —— “链条的坚固程度取决于它最薄弱的环节。”

渲染管线的核⼼功能就是利⽤给定的虚拟相机、三维物体、光源等信息，来⽣成或者渲染（render）⼀张⼆维图像。

类比流水线，但是整个流⽔线的效率会被执⾏速度最慢的那个阶段所影响

{% asset_img 流水线阶段.png 1212%}

### 渲染管线的架构

1. 应用阶段 （application） 
   运行在CPU，并行，⼀般CPU 会负责碰撞检测，全局加速算法，动画，物理模拟等任务
2. 几何处理阶段（geometry processing）
   运行在GPU，负责处理变换（transform），投影（projection）以及其他所有和⼏何处理相关的任务。这个阶段需要计算哪些物体会被绘制，应该如何进⾏绘制，以及应当在哪⾥绘制等问题。
3. 光栅化阶段（rasterization）
   运行在GPU，将构成⼀个三⻆形的三个顶点作为输⼊，找到所有位于三⻆形内部的像素，并将其转发到下⼀个阶段中。
4. 像素处理阶段（pixel processing）
   运行在GPU，决定每个像素的颜色，执行深度测试，判断像素是否可见

### 应用阶段 （application）
开发者可控制，修改程序，提高程序性能表现，如通过算法减少后续需要渲染的三角形数量。也可以通过计算着色器（compute shader）的独⽴模式，让GPU作为通用处理器来进行辅助计算。最后，要将需要渲染的集合物体输入到几何处理阶段。

碰撞检测，检测到碰撞后，产生相应的的响应，并返回给碰撞物体

处理其他来源的输入，如鼠标，键盘，头戴显示器等

### 几何处理阶段（geometry processing）
{% asset_img 几何处理阶段.png 1212%}
#### 顶点着色
两个任务，1.计算顶点位置 2.计算开发人员想要输出的参数，如法线，纹理坐标
顶点位置计算过程
1. 模型坐标，即初始坐标，无任何变换，可以方便的调整自身位置和朝向等，目前的坐标系为**模型坐标系**
2. 模型坐标经过模型变换，得到了世界坐标，世界空间是唯一的，各个模型经过各自的模型变换后，所有的模型就位于同一个空间中，目前的坐标系为**世界坐标系**
3. 为了方便之后的投影操作和裁剪操作，世界坐标需要经过视图变换，得到视图坐标，其目的是为了将相机放在原点，并调整相机的朝向看向-Z，同时y轴指向上，x指向右，如此变换，形成相机空间（camera space），也可以叫做观察空间（view space），或者是眼睛空间（eye space），目前的坐标系为**视图坐标系**，也有人叫**相机坐标系**，**眼睛坐标系**
   {% asset_img 相机变换.png 1212%}
4. 通过投影矩阵将眼睛/视图/相机坐标，投影到裁剪空间（clipping space）中，有两种投影方法，正交投影，透视投影（近大远小），目前的坐标系为**裁剪坐标系（clip coordinates）**。坐标的z分量并不会被存储在⽣成的图像中，而是存储在⼀个叫做 z-buffer 的地方，通过这种⽅式，模型便从三维空间投影到了⼆维空间中。
#### 顶点处理
完成顶点处理后，还有几个可以在GPU上执行的可选操作，顺序如下  曲⾯细分（tessellation）、⼏何着⾊（geometry shading）和流式输出（stream out）。是否使⽤这些可选操作，⼀⽅⾯取决于硬件的功能（并不是所有 GPU 都⽀持这些功能），另⼀⽅⾯取决于程序员的意愿。这些功能相互独⽴，⽽且⼀般并不是很常⽤
1. 曲面细分
   场景中的相机位置可以⽤来决定需要⽣成多少个三⻆形：当距离相机很近时，则⽣成较多数量的三⻆形；当距离相机很远时，则⽣成较少数量的三⻆形。
2. ⼏何着⾊器（geometry shader）
   ⼏何着⾊器有好⼏种⽤途，其中最流⾏的⼀种就是⽤来⽣成粒⼦。想象我们正在模拟⼀个烟花爆炸的过程，每颗⽕花都可以表示为⼀个点，即⼀个简单的顶点。⼏何着⾊器可以将每个顶点都转换成⼀个正⽅形（由两个三⻆形组成），这个正⽅形会始终⾯朝观察者，并且会占据若⼲个像素，这为我们提供了⼀个更加令⼈信服的图元来进⾏后续的着⾊。
3. 流式输出（stream out）
   这个阶段可以让我们把 GPU 作为⼀个**⼏何引擎**，我们可以选择将这些处理好的数据输⼊到⼀个**缓冲区**中，⽽不是将其直接输⼊到渲染管线的后续部分并直接输出到屏幕上，这些缓冲区中的数据可以被CPU 读回使⽤，也可以被 GPU 本身的后续步骤使⽤。
#### 裁剪
在可视范围内的图元，才需要被发送到下一个阶段，光栅化，可视范围外的则不会被发送，对于一部分位于可是空间内部，一部分在外部的图元，需要进行**裁剪**操作，由于我们使用投影矩阵将可视空间变换为标准立方，所有图元都需要被标准立方体裁剪
{% asset_img 裁剪.png 1212%}
#### 屏幕映射

### 光栅化阶段（rasterization）
光栅化也被称为扫描变换（scan conversion），这是⼀个将屏幕空间中**⼆维顶点，转换到屏幕上像素**的过程
可以使⽤点采样（point sample）来判定某个点是否位于三⻆形内部。最简单的⽅式就是直接将每个像素的中⼼点来作为该像素的样本，如果该像素的中⼼点位于三⻆形内部的话，那么我们就认为该像素也位于三⻆形的内部。我们还可以通过超采样（supersampling）或者多重采样抗锯⻮技术（multisampling antialiasing），来对每个像素进⾏多次采样

### 像素处理阶段（pixel processing）
